import os
import faiss
import pickle
import numpy as np
import unicodedata
import re
from openai import OpenAI
from dotenv import load_dotenv
from sentence_transformers import SentenceTransformer

# Cargar variables de entorno
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# Modelo de embeddings
modelo = SentenceTransformer("all-MiniLM-L6-v2")

# Cargar Ã­ndice FAISS y metadatos
base_dir = os.path.dirname(__file__)
index = faiss.read_index(os.path.join(base_dir, "../data/indice_faiss.index"))

with open(os.path.join(base_dir, "../data/metadata_articulos.pkl"), "rb") as f:
    metadata = pickle.load(f)

# ğŸ”¤ FunciÃ³n para normalizar texto (elimina tildes, signos raros, y pasa todo a minÃºsculas)
def normalizar_texto(texto):
    texto = texto.lower()
    texto = ''.join(c for c in unicodedata.normalize('NFD', texto) if unicodedata.category(c) != 'Mn')
    texto = re.sub(r"[^a-z0-9\s]", "", texto)
    return texto.strip()

# ğŸ” Buscar artÃ­culos similares usando FAISS y texto normalizado
def buscar_articulo_similar(pregunta, top_k=10):
    pregunta_normalizada = normalizar_texto(pregunta)
    embedding = modelo.encode([pregunta_normalizada])
    _, indices = index.search(np.array(embedding), top_k)
    resultados = [metadata[i] for i in indices[0]]
    return [r for r in resultados if len(r.get("contenido", "").strip()) > 30]

# ğŸ’¬ Consultar a OpenAI con los artÃ­culos relevantes como contexto
def consultar_openai(pregunta, contexto):
    mensajes = [
        {
            "role": "system",
            "content": f"""
Eres un asistente acadÃ©mico especializado en los reglamentos RAC-01 y RAC-02 de la Escuela Militar de IngenierÃ­a.

Tu Ãºnica fuente de informaciÃ³n debe ser el siguiente contenido textual extraÃ­do directamente de los reglamentos. Debes responder de manera clara, completa y en estilo conversacional, citando literalmente lo que corresponda.

âš ï¸ Si no encuentras la respuesta en el contexto proporcionado, responde exactamente: â€œNo se especifica en estos artÃ­culos del reglamento.â€

ğŸ“„ Fragmentos del reglamento:
{contexto}
""".strip()
        },
        {
            "role": "user",
            "content": pregunta
        }
    ]

    try:
        respuesta = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=mensajes,
            max_tokens=1024,
            temperature=0.2
        )
        return respuesta.choices[0].message.content.strip()
    except Exception as e:
        return f"[ERROR] No se pudo consultar OpenAI: {e}"

# ğŸ” FunciÃ³n principal que responde usando embeddings + contexto + OpenAI
def responder_con_faiss_y_openai(pregunta):
    print("ğŸ” Buscando artÃ­culos mÃ¡s relevantes en FAISS...")
    articulos_utiles = buscar_articulo_similar(pregunta, top_k=10)

    # Si no encuentra, intentar buscar con palabras clave manuales
    if not articulos_utiles:
        claves = ["admisiÃ³n", "permisos", "derechos", "obligaciones", "inasistencia", "evaluaciÃ³n", "estudiante militar"]
        for clave in claves:
            if clave in normalizar_texto(pregunta):
                print(f"ğŸ” Reintentando bÃºsqueda con palabra clave: {clave}")
                articulos_utiles = buscar_articulo_similar(clave, top_k=10)
                break

    if not articulos_utiles:
        return "No se encontrÃ³ informaciÃ³n suficiente en los artÃ­culos del reglamento para responder esta pregunta."

    contexto = "\n\n".join([
        f"[{art.get('rac', 'RAC-?')}] {art.get('articulo', '')} - {art.get('titulo', '')}\n{art.get('contenido', '').strip()}"
        for art in articulos_utiles
    ])

    print("ğŸ¤– Consultando OpenAI con contexto relevante...")
    print("ğŸ“„ Pregunta:", pregunta)
    print("ğŸ“„ Fragmento del contexto:\n", contexto[:500], "...")

    return consultar_openai(pregunta, contexto)
